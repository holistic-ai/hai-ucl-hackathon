<h1 align="center">
<img src="logo.png" width="300">
<br>
Holistic AI x UCL AI Society Hackathon 2024
</h1>

Website: [Holistic AI UCL Hackathon](https://hackathon.holisticai.com/)

Welcome to the **Holistic AI x UCL AI Society Hackathon 2024**! This repository contains all the code, datasets, and resources needed to participate. Whether you're a seasoned data scientist or a beginner with no coding experience, we've got you covered.

- **Join the hackathon’s communication channels**:  
  For live support from mentors during the event, join our Slack community:  
  [Holistic AI Community Slack](https://join.slack.com/t/holisticaicommunity/shared_invite/zt-2jamouyrn-BrMfeoBZIHT8HbLzB3P9QQ)


## Track 1: Multi-Objective Optimization for AI Trustworthiness in Tabular Data Classification

### Goal

The goal of this track is to **develop a multi-objective optimization algorithm** that improves the **trustworthiness** of AI models in tabular data classification tasks. Participants will design algorithms to simultaneously optimize:

- **Performance**: Ensure the AI model achieves high accuracy and effectiveness in predicting outcomes based on the dataset provided.

- **Fairness**: Focus on identifying and mitigating systemic biases in AI systems to ensure equitable outcomes for all users across diverse populations.

- **Robustness**: Measure the model’s ability to perform reliably under varied scenarios, including generalization, adaptability, and resistance to adversarial conditions.

- **Privacy**: Protect data and systems from unauthorized access, misuse, or threats to confidentiality and integrity.

- **Security**: Strengthen the AI system's defense against vulnerabilities and unauthorized access to ensure its safe use in real-world applications.

- **Explainability**: Emphasize understanding and interpreting model decisions, fostering trust and accountability through clear reasoning pathways.

- **Sustainability**: Examine the resource impact of AI systems, including energy efficiency, carbon footprint, and their societal and regulatory implications.


## Track 2: Building Trustworthy Models for Stereotype Classification in Text Data


### Goal

The goal of this track is to build **ethical and trustworthy AI systems** for detecting stereotypes in text data. Participants will work with the **Expanded Multi-Grain Stereotype Dataset (EMGSD)** to classify text as:
- Containing **stereotypes**
- Being **neutral**
- Being **unrelated**

Participants can start with methods from the **HEARTS framework** outlined in the following paper: [HEARTS Framework Paper](https://arxiv.org/abs/2409.11579)


The track also emphasizes addressing key ethical considerations:

- **Performance**: Ensure the AI model achieves high accuracy and effectiveness in predicting outcomes based on the dataset provided.

- **Fairness**: Focus on identifying and mitigating systemic biases in AI systems to ensure equitable outcomes for all users across diverse populations.

- **Robustness**: Measure the model’s ability to perform reliably under varied scenarios, including generalization, adaptability, and resistance to adversarial conditions.

- **Privacy**: Protect data and systems from unauthorized access, misuse, or threats to confidentiality and integrity.

- **Security**: Strengthen the AI system's defense against vulnerabilities and unauthorized access to ensure its safe use in real-world applications.

- **Explainability**: Emphasize understanding and interpreting model decisions, fostering trust and accountability through clear reasoning pathways.

- **Sustainability**: Examine the resource impact of AI systems, including energy efficiency, carbon footprint, and their societal and regulatory implications.